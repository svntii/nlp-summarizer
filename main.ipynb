{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import copy\n",
    "from utils import *\n",
    "from models import *\n",
    "import random\n",
    "import torch\n",
    "import tqdm\n",
    "import sys\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "EMAIL_DETAILS = \"data/email_thread_details.json\"\n",
    "EMAIL_SUMMARIES = \"data/email_thread_summaries.json\"\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_objects = Utils.read_csv(EMAIL_DETAILS, asObject=True, objectType=objects.EMAIL_DETAILS)    \n",
    "summaries_objects = Utils.read_csv(EMAIL_SUMMARIES, asObject=True, objectType=objects.EMAIL_SUMMARIES)\n",
    "\n",
    "if len(email_objects) != len(summaries_objects):\n",
    "    print(\"Error: Length of email objects and summaries objects are not equal\")\n",
    "    sys.exit(1)\n",
    "data_objects = [(email_objects[i], summaries_objects[i]) for i in range(1, len(email_objects))]\n",
    "\n",
    "# Split data into train, test and validation\n",
    "random.shuffle(data_objects)\n",
    "\n",
    "train_data = data_objects[:int(0.8*len(data_objects))]\n",
    "dev_data = data_objects[int(0.8*len(data_objects)):int(0.9*len(data_objects))]\n",
    "vocab = Utils.build_vocab(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_summarizer(model:Summarizer, loss_func, train_set, dev_set, epochs=50, lr=0.0001, device=\"mps\"):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "    model.to(device)\n",
    "    prev_dev_loss = best_dev_loss = None\n",
    "    best_model = model\n",
    "\n",
    "    for epoch in tqdm.tqdm(range(epochs), desc=\"Epoch\"):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        random.shuffle(train_set)\n",
    "        for batch in tqdm.tqdm(train_set, desc=\"Batch\"):\n",
    "            \n",
    "            content = batch[0]\n",
    "            good_summary = batch[1]\n",
    "\n",
    "            content_str = \"\".join([str(o.thread) for o in content])\n",
    "            content_tensor = torch.tensor([model.vocab.numberize(word) for word in content_str.split()], dtype=torch.long)\n",
    "            content_tensor = content_tensor.to(device)\n",
    "            date_tensor = torch.tensor(content[-1].timestamp, dtype=torch.long)\n",
    "            date_tensor = date_tensor.to(device)\n",
    "            good_summary_tensor = torch.tensor([model.vocab.numberize(word) for word in good_summary.summary.split()], dtype=torch.long)\n",
    "            good_summary_tensor = good_summary_tensor.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            summarization = model.summarize(content_tensor, date_tensor, good_summary_tensor)\n",
    "            \n",
    "            loss = loss_func(summarization, good_summary_tensor)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        dev_loss = 0\n",
    "        dev_failed = 0\n",
    "        model.eval()\n",
    "        \n",
    "        dev_summaries = []\n",
    "\n",
    "        for batch in tqdm.tqdm(dev_set, desc=\"Dev Batch\"):\n",
    "            content = batch[0]\n",
    "            content_str = [str(o.thread) for o in content]\n",
    "            good_summary = batch[1]\n",
    "            \n",
    "            summarization = model.summarize(content)\n",
    "            \n",
    "            loss = loss_func(summarization, good_summary)\n",
    "            \n",
    "            dev_loss += loss.item()\n",
    "            \n",
    "            if summarization is None:\n",
    "                dev_failed += 1\n",
    "            else:\n",
    "                dev_summaries.append(summarization)\n",
    "        \n",
    "        print(\"Epoch: \", epoch, \"Loss: \", loss.item())\n",
    "    \n",
    "        if best_dev_loss is None or dev_loss < best_dev_loss:\n",
    "            best_dev_loss = dev_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "            torch.save(best_model.state_dict(), \"models/summarizer.pt\")\n",
    "            print(\"Saved model with dev loss: \", dev_loss)\n",
    "        \n",
    "        if prev_dev_loss is not None and dev_loss > prev_dev_loss:\n",
    "            print('halving learning rate', file=sys.stderr)\n",
    "            optimizer.param_groups[0]['lr'] /= 2\n",
    "        prev_dev_loss = dev_loss\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = Summarizer(input_dim=300, output_dim=300, num_layers=1, num_heads=1, vocab=vocab)\n",
    "model.to(DEVICE)\n",
    "\n",
    "# TODO - figure out which loss function to use\n",
    "best_model = train_model_summarizer(model, nn.CrossEntropyLoss(), train_data, dev_data, epochs=50, lr=0.0001, device=\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_baseline(emailList, s):\n",
    "    for key, value in emailList.items():\n",
    "        print('-------------------')\n",
    "        print(s.summarize(value))\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
