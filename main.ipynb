{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "\n",
    "EMAIL_DETAILS = \"data/email_thread_details.json\"\n",
    "EMAIL_SUMMARIES = \"data/email_thread_summaries.json\"\n",
    "import copy\n",
    "from utils import *\n",
    "from models import *\n",
    "import random\n",
    "import torch\n",
    "import tqdm\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_summarizer(model, loss_func, train_set, dev_set, epochs=50, lr=0.0001, device=\"cpu\"):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "    model.to(device)\n",
    "    prev_dev_loss = best_dev_loss = None\n",
    "    best_model = model\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=\"Epoch\"):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        random.shuffle(train_set)\n",
    "        for batch in tqdm.tqdm(train_set, desc=\"Batch\"):\n",
    "            \n",
    "            content = batch[0]\n",
    "            content = content.to(device)\n",
    "\n",
    "            good_summary = batch[1]\n",
    "            good_summary = good_summary.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            summarization = model.summarize(content)\n",
    "            \n",
    "            loss = loss_func(summarization, good_summary)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        dev_loss = 0\n",
    "        dev_failed = 0\n",
    "        model.eval()\n",
    "        \n",
    "        dev_summaries = []\n",
    "\n",
    "        for batch in tqdm(dev_set, desc=\"Dev Batch\"):\n",
    "            content = batch[0]\n",
    "            content = content.to(device)\n",
    "\n",
    "            good_summary = batch[1]\n",
    "            good_summary = good_summary.to(device)\n",
    "            \n",
    "            summarization = model.summarize(content)\n",
    "            \n",
    "            loss = loss_func(summarization, good_summary)\n",
    "            \n",
    "            dev_loss += loss.item()\n",
    "            \n",
    "            if summarization is None:\n",
    "                dev_failed += 1\n",
    "            else:\n",
    "                dev_summaries.append(summarization)\n",
    "        \n",
    "        print(\"Epoch: \", epoch, \"Loss: \", loss.item())\n",
    "    \n",
    "        if best_dev_loss is None or dev_loss < best_dev_loss:\n",
    "            best_dev_loss = dev_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "            torch.save(best_model.state_dict(), \"models/summarizer.pt\")\n",
    "            print(\"Saved model with dev loss: \", dev_loss)\n",
    "        \n",
    "        if prev_dev_loss is not None and dev_loss > prev_dev_loss:\n",
    "            print('halving learning rate', file=sys.stderr)\n",
    "            optimizer.param_groups[0]['lr'] /= 2\n",
    "        prev_dev_loss = dev_loss\n",
    "\n",
    "    return best_model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_baseline(emailList, s):\n",
    "    for key, value in emailList.items():\n",
    "        print('-------------------')\n",
    "        print(s.summarize(value))\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
