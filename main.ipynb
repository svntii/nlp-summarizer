{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import copy\n",
    "from utils import *\n",
    "from models import *\n",
    "import random\n",
    "import torch\n",
    "import tqdm\n",
    "import sys\n",
    "\n",
    "EMAIL_DETAILS = \"data/email_thread_details.json\"\n",
    "EMAIL_SUMMARIES = \"data/email_thread_summaries.json\"\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_objects = Utils.read_csv(EMAIL_DETAILS, asObject=True, objectType=objects.EMAIL_DETAILS)    \n",
    "summaries_objects = Utils.read_csv(EMAIL_SUMMARIES, asObject=True, objectType=objects.EMAIL_SUMMARIES)\n",
    "\n",
    "if len(email_objects) != len(summaries_objects):\n",
    "    print(\"Error: Length of email objects and summaries objects are not equal\")\n",
    "    sys.exit(1)\n",
    "data_objects = [(email_objects[i], summaries_objects[i]) for i in range(1, len(email_objects))]\n",
    "\n",
    "# Split data into train, test and validation\n",
    "random.shuffle(data_objects)\n",
    "\n",
    "train_data = data_objects[:int(0.8*len(data_objects))]\n",
    "dev_data = data_objects[int(0.8*len(data_objects)):int(0.9*len(data_objects))]\n",
    "vocab = Utils.build_vocab(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_summarizer(model:Summarizer, loss_func, train_set, dev_set, epochs=50, lr=0.0001, device=\"cpu\"):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "    model.to(device)\n",
    "    prev_dev_loss = best_dev_loss = None\n",
    "    best_model = model\n",
    "\n",
    "    for epoch in tqdm.tqdm(range(epochs), desc=\"Epoch\"):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        random.shuffle(train_set)\n",
    "        for batch in tqdm.tqdm(train_set, desc=\"Batch\"):\n",
    "            \n",
    "            content = batch[0]\n",
    "            good_summary = batch[1]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            summarization = model.summarize(content=content, date=content[0].timestamp)\n",
    "            good_summary_tensor = torch.tensor([model.vocab.numberize(word) for word in good_summary.summary.split()])\n",
    "            loss = loss_func(summarization.view(-1, model.n_token), good_summary_tensor)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        dev_loss = 0\n",
    "        dev_failed = 0\n",
    "        model.eval()\n",
    "        dev_summaries = []\n",
    "\n",
    "        # for batch in tqdm.tqdm(dev_set, desc=\"Dev Batch\"):\n",
    "        #     content = batch[0]\n",
    "        #     content_str = [str(o.thread) for o in content]\n",
    "        #     good_summary = batch[1]\n",
    "            \n",
    "        #     summarization = model.summarize(content)\n",
    "            \n",
    "        #     loss = loss_func(summarization.view(-1, nTo)\n",
    "            \n",
    "        #     dev_loss += loss.item()\n",
    "            \n",
    "        #     if summarization is None:\n",
    "        #         dev_failed += 1\n",
    "        #     else:\n",
    "        #         dev_summaries.append(summarization)\n",
    "        \n",
    "        # print(\"Epoch: \", epoch, \"Loss: \", loss.item())\n",
    "    \n",
    "        # if best_dev_loss is None or dev_loss < best_dev_loss:\n",
    "        #     best_dev_loss = dev_loss\n",
    "        #     best_model = copy.deepcopy(model)\n",
    "        #     torch.save(best_model.state_dict(), \"models/summarizer.pt\")\n",
    "        #     print(\"Saved model with dev loss: \", dev_loss)\n",
    "        \n",
    "        # if prev_dev_loss is not None and dev_loss > prev_dev_loss:\n",
    "        #     print('halving learning rate', file=sys.stderr)\n",
    "        #     optimizer.param_groups[0]['lr'] /= 2\n",
    "        # prev_dev_loss = dev_loss\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "nTokens = len(vocab)\n",
    "emb_size = 200\n",
    "n_hidden = 200\n",
    "n_layers = 2\n",
    "n_heads = 2\n",
    "dropout = 0.2\n",
    "model = Summarizer(nTokens,emb_size, n_heads, n_hidden, n_layers, vocab, dropout)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# TODO - figure out which loss function to use\n",
    "best_model = train_model_summarizer(model,loss_func, train_data, dev_data, epochs=50, lr=0.0001, device=\"cpu\")\n",
    "\n",
    "'''\n",
    "    summing over output of nn.transformer\n",
    "\n",
    "    confirm that the output\n",
    "\n",
    "    \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_baseline(emailList, s):\n",
    "    for key, value in emailList.items():\n",
    "        print('-------------------')\n",
    "        print(s.summarize(value))\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
